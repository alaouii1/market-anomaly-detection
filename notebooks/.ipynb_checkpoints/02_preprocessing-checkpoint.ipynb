{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data Preprocessing & Feature Engineering\n",
    "\n",
    "## What is Preprocessing?\n",
    "\n",
    "**Preprocessing** = Preparing raw data before feeding it to ML models.\n",
    "\n",
    "Think of it like cooking:\n",
    "- Raw data = raw ingredients (unwashed vegetables, uncut meat)\n",
    "- Preprocessing = washing, cutting, seasoning\n",
    "- ML model = the oven\n",
    "- You can't put raw ingredients directly in the oven and expect good results!\n",
    "\n",
    "## What is Feature Engineering?\n",
    "\n",
    "**Feature** = A measurable property of your data that the model uses to learn.\n",
    "\n",
    "**Feature Engineering** = Creating NEW useful properties from existing data.\n",
    "\n",
    "Example:\n",
    "- Raw data: `close = 86626.39` (BTC price)\n",
    "- Engineered feature: `return = 0.15%` (price changed by 0.15% from last hour)\n",
    "\n",
    "**Why engineer features?**\n",
    "- Raw price ($86,626) is meaningless alone - is that high? low? \n",
    "- But \"0.15% change\" is meaningful - we can compare it to other hours\n",
    "- ML models learn patterns better from relative/normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 1: IMPORT LIBRARIES\n",
    "# ============================================\n",
    "\n",
    "# pandas: For working with tables (DataFrames)\n",
    "# Think of it like Excel in Python\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: For mathematical operations on arrays\n",
    "# Much faster than regular Python math\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib: For creating charts/plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display settings - show all columns when we print\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 2: LOAD DATA FROM CSV FILES\n",
    "# ============================================\n",
    "\n",
    "# pd.read_csv() reads a CSV file into a DataFrame\n",
    "# Adjust the path based on where your files are!\n",
    "\n",
    "btc = pd.read_csv('../data/raw/BTCUSDT_1h.csv')\n",
    "eth = pd.read_csv('../data/raw/ETHUSDT_1h.csv')\n",
    "\n",
    "# .shape tells us (rows, columns)\n",
    "print(f\"BTC data: {btc.shape[0]} rows, {btc.shape[1]} columns\")\n",
    "print(f\"ETH data: {eth.shape[0]} rows, {eth.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first 5 rows\n",
    "# .head() shows the first N rows (default 5)\n",
    "btc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types of each column\n",
    "# This is important because:\n",
    "# - Numbers should be int64 or float64\n",
    "# - Dates should be datetime64\n",
    "# - Text should be object\n",
    "\n",
    "print(\"Data types:\")\n",
    "print(btc.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check for Missing Values\n",
    "\n",
    "### What are Missing Values?\n",
    "\n",
    "**Missing value** = A cell in your data that has no value (empty).\n",
    "\n",
    "In pandas, missing values are shown as `NaN` (Not a Number).\n",
    "\n",
    "**Why do missing values happen?**\n",
    "- Sensor malfunction\n",
    "- Data not collected\n",
    "- Exchange was down\n",
    "- Error during download\n",
    "\n",
    "**Why are they a problem?**\n",
    "- Most ML models crash when they see NaN\n",
    "- Calculations like mean() ignore NaN, which can skew results\n",
    "- We need to either remove or fill them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHECK FOR MISSING VALUES\n",
    "# ============================================\n",
    "\n",
    "# .isnull() returns True/False for each cell (True = missing)\n",
    "# .sum() counts the True values\n",
    "\n",
    "print(\"=== BTC Missing Values ===\")\n",
    "print(btc.isnull().sum())\n",
    "print(f\"\\nTotal missing cells: {btc.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\n=== ETH Missing Values ===\")\n",
    "print(eth.isnull().sum())\n",
    "print(f\"\\nTotal missing cells: {eth.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Handle Missing Values (if we had any)\n",
    "\n",
    "There are 3 main strategies:\n",
    "\n",
    "| Strategy | Code | When to use |\n",
    "|----------|------|-------------|\n",
    "| **Delete rows** | `df.dropna()` | When you have lots of data and few missing rows |\n",
    "| **Fill with previous value** | `df.fillna(method='ffill')` | Good for time series (price stays same until next update) |\n",
    "| **Fill with average** | `df['col'].fillna(df['col'].mean())` | When order doesn't matter |\n",
    "\n",
    "For financial time series, **forward fill** is usually best because:\n",
    "- If we don't have a new price, the old price is still valid\n",
    "- Deleting rows creates gaps in our timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example (we don't need this if data is complete, but good to know)\n",
    "\n",
    "# If we had missing values, we would do:\n",
    "# btc = btc.fillna(method='ffill')  # Forward fill\n",
    "\n",
    "# Or to delete rows with any missing value:\n",
    "# btc = btc.dropna()\n",
    "\n",
    "print(\"No missing values found - we can proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert Timestamp to Datetime\n",
    "\n",
    "### What is a Datetime object?\n",
    "\n",
    "Right now, our `timestamp` column is just text (a \"string\"):\n",
    "- `\"2025-12-17 05:00:00\"` - Python sees this as letters, not a date\n",
    "\n",
    "We need to convert it to a **datetime** object so Python understands it's a date/time:\n",
    "- Can extract year, month, day, hour\n",
    "- Can calculate differences between dates\n",
    "- Charts will show proper date axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current type of timestamp\n",
    "print(\"Current type:\", type(btc['timestamp'].iloc[0]))\n",
    "print(\"Sample value:\", btc['timestamp'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONVERT TIMESTAMP TO DATETIME\n",
    "# ============================================\n",
    "\n",
    "# pd.to_datetime() converts strings to datetime objects\n",
    "btc['timestamp'] = pd.to_datetime(btc['timestamp'])\n",
    "eth['timestamp'] = pd.to_datetime(eth['timestamp'])\n",
    "\n",
    "print(\"After conversion:\")\n",
    "print(\"Type:\", type(btc['timestamp'].iloc[0]))\n",
    "print(\"Sample value:\", btc['timestamp'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can easily get info from the datetime\n",
    "print(\"Data date range:\")\n",
    "print(f\"  Start: {btc['timestamp'].min()}\")\n",
    "print(f\"  End:   {btc['timestamp'].max()}\")\n",
    "print(f\"  Total days: {(btc['timestamp'].max() - btc['timestamp'].min()).days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering\n",
    "\n",
    "Now the important part! We'll create new features that help detect anomalies.\n",
    "\n",
    "### Why can't we use raw prices?\n",
    "\n",
    "**Problem:** BTC price changes over time:\n",
    "- 2015: BTC = $200\n",
    "- 2021: BTC = $60,000\n",
    "- 2024: BTC = $90,000\n",
    "\n",
    "A $1000 price move:\n",
    "- In 2015: That's 500% of the price! HUGE anomaly!\n",
    "- In 2024: That's 1.1% of the price. Pretty normal.\n",
    "\n",
    "**Solution:** Use **relative** features (percentages) instead of absolute values.\n",
    "\n",
    "---\n",
    "\n",
    "### Features We'll Create:\n",
    "\n",
    "| Feature | What it measures | Why useful for anomaly detection |\n",
    "|---------|------------------|----------------------------------|\n",
    "| **Return** | % price change from last hour | Detects sudden price jumps |\n",
    "| **Log Return** | Same but with logarithm | Better statistical properties |\n",
    "| **Volatility** | How wildly price moves | Detects unstable periods |\n",
    "| **Volume Change** | % change in trading volume | Detects unusual trading activity |\n",
    "| **Volume Ratio** | Current volume vs average | Detects volume spikes |\n",
    "| **Price Range** | High-Low as % of price | Detects volatile candles |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1: Return (Price Change %)\n",
    "\n",
    "**What is it?**\n",
    "How much the price changed from the previous hour, as a percentage.\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "return = (current_price - previous_price) / previous_price × 100\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "- Previous close: $86,626\n",
    "- Current close: $86,778\n",
    "- Return = (86778 - 86626) / 86626 × 100 = **0.175%**\n",
    "\n",
    "**Why useful?**\n",
    "- Normal hours: return is between -1% and +1%\n",
    "- Anomaly: return is -5% or +5% (something big happened!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE 1: RETURN (PERCENTAGE PRICE CHANGE)\n",
    "# ============================================\n",
    "\n",
    "# .pct_change() calculates percentage change from previous row\n",
    "# Multiply by 100 to get percentage (0.01 -> 1%)\n",
    "\n",
    "btc['return'] = btc['close'].pct_change() * 100\n",
    "eth['return'] = eth['close'].pct_change() * 100\n",
    "\n",
    "# Let's verify with manual calculation\n",
    "print(\"Verify return calculation:\")\n",
    "print(f\"Row 0 close: {btc['close'].iloc[0]}\")\n",
    "print(f\"Row 1 close: {btc['close'].iloc[1]}\")\n",
    "manual_return = (btc['close'].iloc[1] - btc['close'].iloc[0]) / btc['close'].iloc[0] * 100\n",
    "print(f\"Manual calculation: {manual_return:.4f}%\")\n",
    "print(f\"pct_change result: {btc['return'].iloc[1]:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the return distribution\n",
    "print(\"BTC Return Statistics:\")\n",
    "print(btc['return'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2: Log Return\n",
    "\n",
    "**What is it?**\n",
    "Same as return, but using natural logarithm.\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "log_return = ln(current_price / previous_price) × 100\n",
    "```\n",
    "\n",
    "**Why use log instead of regular return?**\n",
    "\n",
    "1. **Additive property**: Log returns can be added across time periods\n",
    "   - Regular: If day1 = +10% and day2 = -10%, total ≠ 0% (it's -1%)\n",
    "   - Log: If day1 = +10% and day2 = -10%, total = 0% exactly\n",
    "\n",
    "2. **More symmetric**: Regular returns are bounded at -100% (can't lose more than everything) but unbounded above. Log returns are symmetric.\n",
    "\n",
    "3. **Better for statistics**: Log returns are closer to normal distribution.\n",
    "\n",
    "**For small changes (<5%), regular and log returns are almost identical.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE 2: LOG RETURN\n",
    "# ============================================\n",
    "\n",
    "# np.log() is natural logarithm\n",
    "# .shift(1) gets the previous row's value\n",
    "\n",
    "btc['log_return'] = np.log(btc['close'] / btc['close'].shift(1)) * 100\n",
    "eth['log_return'] = np.log(eth['close'] / eth['close'].shift(1)) * 100\n",
    "\n",
    "# Compare regular vs log return\n",
    "print(\"Regular return vs Log return (first 10 rows):\")\n",
    "print(btc[['close', 'return', 'log_return']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 3: Volatility (Rolling Standard Deviation)\n",
    "\n",
    "**What is Volatility?**\n",
    "How much the returns vary/fluctuate over a period of time.\n",
    "\n",
    "**What is Rolling?**\n",
    "\"Rolling\" means we calculate over a moving window:\n",
    "- For row 24: calculate using rows 1-24\n",
    "- For row 25: calculate using rows 2-25\n",
    "- For row 26: calculate using rows 3-26\n",
    "- ...and so on\n",
    "\n",
    "It's like a sliding window that moves through your data.\n",
    "\n",
    "**What is Standard Deviation (std)?**\n",
    "Measures how spread out numbers are from their average.\n",
    "- Low std = numbers are close together (stable)\n",
    "- High std = numbers are spread out (volatile)\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "volatility_24h = std(last 24 returns)\n",
    "```\n",
    "\n",
    "**Why useful?**\n",
    "- Normal times: volatility is low (0.3-0.5%)\n",
    "- Crisis/anomaly: volatility spikes (1-3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE 3: VOLATILITY (ROLLING STD OF RETURNS)\n",
    "# ============================================\n",
    "\n",
    "# .rolling(window=24) creates a 24-hour rolling window\n",
    "# .std() calculates standard deviation of that window\n",
    "\n",
    "btc['volatility_24h'] = btc['return'].rolling(window=24).std()\n",
    "eth['volatility_24h'] = eth['return'].rolling(window=24).std()\n",
    "\n",
    "# Note: First 23 rows will be NaN (not enough data for 24-hour window)\n",
    "print(\"Volatility (first 30 rows):\")\n",
    "print(btc[['timestamp', 'return', 'volatility_24h']].head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** The first 23 rows have `NaN` for volatility. This is because we need 24 values to calculate a 24-hour standard deviation. We'll handle these NaN values later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 4: Volume Change\n",
    "\n",
    "**What is Volume?**\n",
    "The number of BTC traded in that hour.\n",
    "\n",
    "**What is Volume Change?**\n",
    "How much the volume changed from the previous hour, as a percentage.\n",
    "\n",
    "**Why useful?**\n",
    "Sudden volume spikes often indicate something unusual:\n",
    "- Big news announcement\n",
    "- Whale (large trader) activity\n",
    "- Market manipulation\n",
    "- Panic buying/selling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE 4: VOLUME CHANGE (%)\n",
    "# ============================================\n",
    "\n",
    "btc['volume_change'] = btc['volume'].pct_change() * 100\n",
    "eth['volume_change'] = eth['volume'].pct_change() * 100\n",
    "\n",
    "print(\"Volume change statistics:\")\n",
    "print(btc['volume_change'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 5: Volume Ratio (vs 24h Average)\n",
    "\n",
    "**What is it?**\n",
    "Current volume divided by the average volume of the last 24 hours.\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "volume_ratio = current_volume / average(last 24 hours volume)\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- volume_ratio = 1.0 -> Normal volume (same as average)\n",
    "- volume_ratio = 2.0 -> Double the normal volume\n",
    "- volume_ratio = 0.5 -> Half the normal volume\n",
    "- volume_ratio = 5.0 -> 5x normal volume (ANOMALY!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE 5: VOLUME RATIO\n",
    "# ============================================\n",
    "\n",
    "# .rolling(window=24).mean() calculates the 24-hour moving average\n",
    "btc['volume_ratio'] = btc['volume'] / btc['volume'].rolling(window=24).mean()\n",
    "eth['volume_ratio'] = eth['volume'] / eth['volume'].rolling(window=24).mean()\n",
    "\n",
    "print(\"Volume ratio statistics:\")\n",
    "print(btc['volume_ratio'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 6: Price Range\n",
    "\n",
    "**What is it?**\n",
    "The difference between the highest and lowest price in that hour, as a percentage of the close price.\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "price_range = (high - low) / close × 100\n",
    "```\n",
    "\n",
    "**Why useful?**\n",
    "- Normal hour: price_range is 0.2-0.5% (price stays stable)\n",
    "- Volatile hour: price_range is 2-5% (price swings wildly)\n",
    "- This captures intra-hour volatility that returns might miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE 6: PRICE RANGE\n",
    "# ============================================\n",
    "\n",
    "btc['price_range'] = (btc['high'] - btc['low']) / btc['close'] * 100\n",
    "eth['price_range'] = (eth['high'] - eth['low']) / eth['close'] * 100\n",
    "\n",
    "print(\"Price range statistics:\")\n",
    "print(btc['price_range'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Handle NaN Values from Feature Engineering\n",
    "\n",
    "**Problem:** Some of our new features have NaN values:\n",
    "- `return`: Row 0 is NaN (can't calculate change from nothing)\n",
    "- `volatility_24h`: Rows 0-23 are NaN (need 24 rows to calculate)\n",
    "- `volume_ratio`: Rows 0-23 are NaN (same reason)\n",
    "\n",
    "**Solution:** Drop the first 24 rows.\n",
    "\n",
    "**Why is this okay?**\n",
    "- We have 1000 rows\n",
    "- Losing 24 rows = 2.4% of data\n",
    "- Better than having incomplete data that breaks ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many NaN values we have\n",
    "print(\"NaN count per column BEFORE cleaning:\")\n",
    "print(btc.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DROP ROWS WITH NaN VALUES\n",
    "# ============================================\n",
    "\n",
    "rows_before = len(btc)\n",
    "\n",
    "# dropna() removes any row that has at least one NaN\n",
    "btc = btc.dropna()\n",
    "eth = eth.dropna()\n",
    "\n",
    "rows_after = len(btc)\n",
    "\n",
    "print(f\"Rows before: {rows_before}\")\n",
    "print(f\"Rows after:  {rows_after}\")\n",
    "print(f\"Rows removed: {rows_before - rows_after} ({(rows_before - rows_after) / rows_before * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no more NaN\n",
    "print(\"NaN count per column AFTER cleaning:\")\n",
    "print(btc.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index after dropping rows\n",
    "# This makes the index go 0, 1, 2, 3... instead of 24, 25, 26...\n",
    "btc = btc.reset_index(drop=True)\n",
    "eth = eth.reset_index(drop=True)\n",
    "\n",
    "print(\"Index reset. First few rows:\")\n",
    "print(btc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: View Our Engineered Features\n",
    "\n",
    "Let's look at what we've created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns we now have\n",
    "print(\"All columns:\")\n",
    "print(btc.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at our feature columns\n",
    "feature_cols = ['timestamp', 'close', 'return', 'log_return', 'volatility_24h', \n",
    "                'volume_change', 'volume_ratio', 'price_range']\n",
    "\n",
    "print(\"Sample of our features:\")\n",
    "btc[feature_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all features\n",
    "print(\"Feature Statistics:\")\n",
    "btc[['return', 'log_return', 'volatility_24h', 'volume_change', 'volume_ratio', 'price_range']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize the Features\n",
    "\n",
    "Let's plot our features to see their distributions and spot potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "fig.suptitle('BTC Feature Distributions', fontsize=14)\n",
    "\n",
    "# Plot each feature\n",
    "features_to_plot = ['return', 'log_return', 'volatility_24h', \n",
    "                    'volume_change', 'volume_ratio', 'price_range']\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Histogram\n",
    "    ax.hist(btc[feature], bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(feature)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot features over time\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "fig.suptitle('BTC Features Over Time', fontsize=14)\n",
    "\n",
    "# Price\n",
    "axes[0].plot(btc['timestamp'], btc['close'], linewidth=0.8)\n",
    "axes[0].set_title('Price (Close)')\n",
    "axes[0].set_ylabel('USD')\n",
    "\n",
    "# Return\n",
    "axes[1].plot(btc['timestamp'], btc['return'], linewidth=0.8, color='green')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[1].set_title('Return (%)')\n",
    "axes[1].set_ylabel('%')\n",
    "\n",
    "# Volatility\n",
    "axes[2].plot(btc['timestamp'], btc['volatility_24h'], linewidth=0.8, color='orange')\n",
    "axes[2].set_title('24h Volatility')\n",
    "axes[2].set_ylabel('Std Dev')\n",
    "\n",
    "# Volume Ratio\n",
    "axes[3].plot(btc['timestamp'], btc['volume_ratio'], linewidth=0.8, color='purple')\n",
    "axes[3].axhline(y=1, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[3].set_title('Volume Ratio (vs 24h avg)')\n",
    "axes[3].set_ylabel('Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Processed Data\n",
    "\n",
    "Save our preprocessed data so we can use it in the next notebooks for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SAVE PROCESSED DATA\n",
    "# ============================================\n",
    "\n",
    "# Save to CSV\n",
    "btc.to_csv('../data/processed/BTCUSDT_1h_processed.csv', index=False)\n",
    "eth.to_csv('../data/processed/ETHUSDT_1h_processed.csv', index=False)\n",
    "\n",
    "print(\"Data saved!\")\n",
    "print(f\"BTC: {len(btc)} rows, {len(btc.columns)} columns\")\n",
    "print(f\"ETH: {len(eth)} rows, {len(eth.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What we did:\n",
    "1. **Loaded** CSV data into pandas DataFrames\n",
    "2. **Checked** for missing values (none found)\n",
    "3. **Converted** timestamp to proper datetime format\n",
    "4. **Created 6 features:**\n",
    "   - `return` - % price change\n",
    "   - `log_return` - logarithmic return\n",
    "   - `volatility_24h` - rolling standard deviation\n",
    "   - `volume_change` - % volume change\n",
    "   - `volume_ratio` - volume vs 24h average\n",
    "   - `price_range` - high-low as % of price\n",
    "5. **Dropped** rows with NaN values (first 24 rows)\n",
    "6. **Saved** processed data\n",
    "\n",
    "### Next steps:\n",
    "- Implement anomaly detection models (Isolation Forest, One-Class SVM, LOF)\n",
    "- Compare results across models\n",
    "\n",
    "### Key terms to remember:\n",
    "- **Preprocessing**: Cleaning and preparing raw data\n",
    "- **Feature Engineering**: Creating new useful columns from existing data\n",
    "- **Rolling window**: Calculating over a moving subset of data\n",
    "- **NaN**: Missing value (Not a Number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
