{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Comparison of All Anomaly Detection Methods\n",
    "\n",
    "## Final Step: Compare and Analyze Results\n",
    "\n",
    "This notebook:\n",
    "1. Loads results from all 4 methods\n",
    "2. Compares how many anomalies each found\n",
    "3. Analyzes consensus (agreement between methods)\n",
    "4. Creates final output with all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Comparison\").master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ALL RESULTS\n",
    "RESULTS_PATH = \"../data/results/\"\n",
    "\n",
    "zscore_df = spark.read.csv(RESULTS_PATH + \"zscore_results\", header=True, inferSchema=True)\n",
    "kmeans_df = spark.read.csv(RESULTS_PATH + \"kmeans_results\", header=True, inferSchema=True)\n",
    "rf_df = spark.read.csv(RESULTS_PATH + \"rf_results\", header=True, inferSchema=True)\n",
    "gmm_df = spark.read.csv(RESULTS_PATH + \"gmm_results\", header=True, inferSchema=True)\n",
    "\n",
    "print(\"All results loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT ANOMALIES PER METHOD\n",
    "total = zscore_df.count()\n",
    "\n",
    "zscore_anomalies = zscore_df.filter(col(\"anomaly_zscore\") == 1).count()\n",
    "kmeans_anomalies = kmeans_df.filter(col(\"anomaly_kmeans\") == 1).count()\n",
    "rf_anomalies = rf_df.filter(col(\"anomaly_rf\") == 1).count()\n",
    "gmm_anomalies = gmm_df.filter(col(\"anomaly_gmm\") == 1).count()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total points: {total}\")\n",
    "print(f\"Z-Score:      {zscore_anomalies} ({100*zscore_anomalies/total:.1f}%)\")\n",
    "print(f\"K-Means:      {kmeans_anomalies} ({100*kmeans_anomalies/total:.1f}%)\")\n",
    "print(f\"Random Forest:{rf_anomalies} ({100*rf_anomalies/total:.1f}%)\")\n",
    "print(f\"GMM:          {gmm_anomalies} ({100*gmm_anomalies/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN ALL RESULTS\n",
    "combined = zscore_df.select(\"row_id\", \"timestamp\", \"close\", \"return\", \"anomaly_zscore\")\n",
    "combined = combined.join(kmeans_df.select(\"row_id\", \"anomaly_kmeans\"), \"row_id\")\n",
    "combined = combined.join(rf_df.select(\"row_id\", \"anomaly_rf\"), \"row_id\")\n",
    "combined = combined.join(gmm_df.select(\"row_id\", \"anomaly_gmm\"), \"row_id\")\n",
    "\n",
    "# Calculate votes\n",
    "combined = combined.withColumn(\n",
    "    \"votes\",\n",
    "    col(\"anomaly_zscore\") + col(\"anomaly_kmeans\") + col(\"anomaly_rf\") + col(\"anomaly_gmm\")\n",
    ")\n",
    "\n",
    "print(\"Consensus (how many methods agree):\")\n",
    "combined.groupBy(\"votes\").count().orderBy(\"votes\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL LABEL (2+ methods = anomaly)\n",
    "combined = combined.withColumn(\n",
    "    \"final_label\",\n",
    "    when(col(\"votes\") >= 2, \"ANOMALY\").otherwise(\"Normal\")\n",
    ")\n",
    "\n",
    "final_anomalies = combined.filter(col(\"final_label\") == \"ANOMALY\").count()\n",
    "print(f\"\\nHigh-confidence anomalies (2+ methods): {final_anomalies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW TOP ANOMALIES\n",
    "print(\"Top anomalies:\")\n",
    "combined.filter(col(\"votes\") >= 2).orderBy(col(\"votes\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FINAL RESULTS\n",
    "output = RESULTS_PATH + \"final_results\"\n",
    "combined.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(output)\n",
    "print(f\"Saved to: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROJECT COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
